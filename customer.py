# -*- coding: utf-8 -*-
"""Customer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10lDznSTXwKfA-NMNAMUp4nbZ2dWZMjR1
"""

# Importing necessary libraries
import pandas as pd

# Load dataset
df = pd.read_csv('Mall_Customers.csv')

# Menampilkan statistik deskriptif dan informasi dataset
dataset_info = df.info()
statistik_deskriptif = df.describe()

# Menampilkan 5 baris pertama dataset untuk pemeriksaan awal
df_head = df.head()

dataset_info, statistik_deskriptif, df_head

import matplotlib.pyplot as plt
import seaborn as sns

# Setting style for the plots
sns.set(style="whitegrid")

# 1. Visualisasi distribusi usia
plt.figure(figsize=(16, 12))

plt.subplot(2, 2, 1)
sns.histplot(df['Age'], bins=20, kde=True, color='blue')
plt.title('Distribusi Usia')

# 2. Visualisasi distribusi pendapatan tahunan
plt.subplot(2, 2, 2)
sns.histplot(df['Annual Income (k$)'], bins=20, kde=True, color='green')
plt.title('Distribusi Pendapatan Tahunan (k$)')

# 3. Visualisasi distribusi skor pengeluaran
plt.subplot(2, 2, 3)
sns.histplot(df['Spending Score (1-100)'], bins=20, kde=True, color='purple')
plt.title('Distribusi Skor Pengeluaran (1-100)')

# 4. Visualisasi distribusi gender
plt.figure(figsize=(6, 4))
sns.countplot(x='Gender', hue='Gender', data=df, palette='Set1', legend=False)  # Assign 'x' to 'hue' and set 'legend=False'
plt.title('Distribusi Gender')
plt.show()

plt.tight_layout()
plt.show()

# Memeriksa nilai NaN dalam dataset
cek_nan = df.isnull().sum()

# Deteksi outlier menggunakan boxplot untuk kolom numerik
plt.figure(figsize=(12, 8))

# Boxplot untuk Age
plt.subplot(1, 3, 1)
sns.boxplot(x=df['Age'], color='lightblue')
plt.title('Outlier pada Usia')

# Boxplot untuk Annual Income
plt.subplot(1, 3, 2)
sns.boxplot(x=df['Annual Income (k$)'], color='lightgreen')
plt.title('Outlier pada Pendapatan Tahunan')

# Boxplot untuk Spending Score
plt.subplot(1, 3, 3)
sns.boxplot(x=df['Spending Score (1-100)'], color='lightcoral')
plt.title('Outlier pada Skor Pengeluaran')

plt.tight_layout()
plt.show()

cek_nan

"""## Splitting Data & Preprocessing:"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Convert 'Gender' to numerical
df['Gender'] = LabelEncoder().fit_transform(df['Gender'])

# Add 'Spending_Category': 1 for high spending, 0 for low spending
df['Spending_Category'] = df['Spending Score (1-100)'].apply(lambda x: 1 if x > 50 else 0)

# Define features and target
X = df[['Gender', 'Age', 'Annual Income (k$)']]
y = df['Spending_Category']

# Split data into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""##  Training Model"""

from sklearn.metrics import accuracy_score

# 2. Linear Regression
linreg = LinearRegression()
linreg.fit(X_train, y_train)
y_pred_linreg = linreg.predict(X_test)
y_pred_linreg = [1 if y > 0.5 else 0 for y in y_pred_linreg]  # Thresholding for classification
linreg_acc = accuracy_score(y_test, y_pred_linreg)

# Menghitung akurasi untuk Linear Regression
linreg_acc_decimal = accuracy_score(y_test, y_pred_linreg)

# Menampilkan hasil akurasi dalam bentuk desimal
print(f"Akurasi Linear Regression: {linreg_acc_decimal:.4f}")

# 3. Logistic Regression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
logreg_acc = accuracy_score(y_test, y_pred_logreg)

# Menghitung akurasi untuk Logistic Regression
logreg_acc_decimal = accuracy_score(y_test, y_pred_logreg)

# Menampilkan hasil akurasi dalam bentuk desimal
print(f"Akurasi Logistic Regression: {logreg_acc_decimal:.4f}")

# 4. K-NN
knn = KNeighborsClassifier(n_neighbors=5)  # You can change the value of 'k'
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
knn_acc = accuracy_score(y_test, y_pred_knn)

# Menghitung akurasi untuk K-NN
knn_acc_decimal = accuracy_score(y_test, y_pred_knn)

print(f"Akurasi K-NN: {knn_acc_decimal:.4f}")

# 5. Displaying accuracy results
print(f"Accuracy of Linear Regression: {linreg_acc * 100:.2f}%")
print(f"Accuracy of Logistic Regression: {logreg_acc * 100:.2f}%")
print(f"Accuracy of K-NN: {knn_acc * 100:.2f}%")

"""## Evaluating the Model:"""

from sklearn.metrics import confusion_matrix, classification_report

# Menyimpan hasil akurasi dalam dictionary
results = {
    'Linear Regression': linreg_acc * 100,
    'Logistic Regression': logreg_acc * 100,
    'K-NN': knn_acc * 100
}

# Menentukan model dengan akurasi tertinggi
best_model = max(results, key=results.get)

# Menampilkan hasil akhir
print("\n=== Kesimpulan ===")
for model, acc in results.items():
    print(f"Akurasi {model}: {acc:.2f}%")

print(f"\nModel dengan akurasi tertinggi: {best_model} dengan akurasi {results[best_model]:.2f}%")

# Justifikasi model terbaik
print("\n=== Alasan Memilih Model ===")
if best_model == 'Linear Regression':
    print("Model Linear Regression dipilih karena memiliki akurasi tertinggi. Meski digunakan untuk regresi, dengan thresholding, model ini dapat memprediksi dengan baik.")
    # Evaluasi model terbaik
    print("Confusion Matrix dan Classification Report untuk Linear Regression:")
    print(confusion_matrix(y_test, y_pred_linreg))
    print(classification_report(y_test, y_pred_linreg))

elif best_model == 'Logistic Regression':
    print("Model Logistic Regression dipilih karena cocok untuk klasifikasi biner dan memiliki akurasi tertinggi.")
    # Evaluasi model terbaik
    print("Confusion Matrix dan Classification Report untuk Logistic Regression:")
    print(confusion_matrix(y_test, y_pred_logreg))
    print(classification_report(y_test, y_pred_logreg))

elif best_model == 'K-NN':
    print("Model K-NN dipilih karena akurasinya tertinggi, dan cocok untuk prediksi berbasis tetangga terdekat.")
    # Evaluasi model terbaik
    print("Confusion Matrix dan Classification Report untuk K-NN:")
    print(confusion_matrix(y_test, y_pred_knn))
    print(classification_report(y_test, y_pred_knn))

"""## algoritma K-Means"""

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Dataset hanya mencakup fitur numerik yang relevan
data = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]

# Menerapkan Elbow Method
ssd = []
K_range = range(1, 11)  # Menguji dari 1 hingga 10 cluster

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    ssd.append(kmeans.inertia_)  # inertia_ adalah SSD

# Visualisasi Elbow Method
plt.figure(figsize=(8, 5))
plt.plot(K_range, ssd, 'o-', color='red')  # Removed redundant 'marker' and 'color' definitions
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Sum of Squared Distances (SSD)')
plt.show()

from sklearn.preprocessing import StandardScaler

# Memilih fitur numerik yang ingin di-scaling
X = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]

# Melakukan scaling pada fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Melakukan K-Means clustering dengan k=3 (misalnya)
kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Menambahkan kolom hasil cluster ke dataset
df['Cluster'] = clusters

# Visualisasi hasil cluster dengan scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap='viridis', marker='o', s=50, alpha=0.7)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', label='Centroids')
plt.title('K-Means Clustering')
plt.xlabel('Age (scaled)')
plt.ylabel('Annual Income (scaled)')
plt.legend()
plt.show()